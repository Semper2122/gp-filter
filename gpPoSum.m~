function [M, S, V] = gpPoSum(X, input, target, m, s)  %m and s are a set of means and variances!, same for M and S
%
% Compute joint predictions for multiple GPs with uncertain inputs.
%
% compute exact mean and exact covariance matrix of predictive distribution
%
% X       (column) vector of length E*(D+2)
% input   n by D matrix of inputs
% target  n by E matrix of targets
% m       (column) vector of length D, mean of the test distribution
% s       D by D covariance matrix of the test distribution
% M       (column) vector of length E, mean of the predictive distribution
% S       E by E matrix, covariance of the predictive distribution
% V       D by E covariance between inputs and prediction
%
% compute
% E[p(f(x)|m,s)]
% S[p(f(x)|m,s)]
% cov(x,f(x)|m,s)
%
% includes:
% a) uncertainty about the underlying function (in prediction)
% b) measurement/system noise in the predictive covariance
%
% Copyright (C) 2008-2009 by Marc Peter Deisenroth and Carl Edward Rasmussen,
% 2009-06-25


persistent K iK oldX;
[n, D] = size(input);          % number of examples and dimension of input space
[n, E] = size(target);                % number of examples and number of outputs
X = reshape(X, D+2, E)';


m_vec = m;
s_vec = s;


% if necessary: re-compute cashed variables
if numel(X) ~= numel(oldX) || isempty(iK) || sum(any(X ~= oldX)) || numel(iK)~=E*n^2 
  oldX = X;                                               
  iK = zeros(n,n,E); K = iK;
  for i=1:E
    inp = bsxfun(@rdivide,input,exp(X(i,1:D)));
    K(:,:,i) = exp(2*X(i,D+1)-maha(inp,inp)/2);
    L = chol(K(:,:,i)+exp(2*X(i,D+2))*eye(n))';
    iK(:,:,i) = L'\(L\eye(n));
  end
end
k = zeros(n,E); beta = k; M = zeros(E,1); V = zeros(D,E); S = zeros(E);

inp = bsxfun(@minus,input,m_vec'); % resta m a totes les entrades de input... ok! repmat power
beta = (K(:,:,1)+exp(2*X(1,D+2))*eye(n))\target(:,1);
R = s_vec'+diag(exp(2*X(1,1:D))); t = inp./R;  %HERE
l = exp(-(t.*inp)/2); lb = l.*beta;
c = exp(2*X(1,D+1))./sqrt(R)*exp(sum(X(1,1:D)));  %HERE
M = sum(lb).*c;                                             % predicted mean
V = s_vec'.*c.*sum(t.*lb);  %HERE                                % input output covariance
v = bsxfun(@rdivide,inp,exp(X(1,1:D))); k = 2*X(1,D+1)-v.*v/2;

ii = bsxfun(@rdivide,inp,exp(2*X(1,1:D)));
RR = s_vec'*diag(exp(-2*X(1,1:D))+exp(-2*X(1,1:D)))+eye(D); tt = 1./sqrt(R);
ij = bsxfun(@rdivide,inp,exp(2*X(1,1:D)));
A = beta*beta'; A = A - iK(:,:,1);
K2 = repmat(k,1, 1, n);
KK = permute(K2, [1,3,2]) + permute(K2, [3,1,2]);

S_vec = M*0;
iiRR = ii.*(s_vec'./RR/2); iRi = iiRR.*ii; %checked and seems correct..
iRi2 = repmat(iRi,1, 1, 200); 
IRI = permute(iRi2, [1,3,2]) + permute(iRi2, [3,1,2]); %checked
IRI2 = permute(repmat(iiRR,1, 1, n),[1,3,2]).*permute(repmat(ii,1, 1, n),[1,3,2]);
II = IRI+2*IRI2;
L = exp(KK+II);
AA = tt*0;
%iRj = -ij.*(s_vec'./RR/2).*(-ij);
tic
for jj =1:length(m_vec)
%i = 1; 
%j = 1;
%L = exp(KK(:,:,jj)+IRI(:,:,jj)+2*(ii(:,jj)*(RR(jj)\s_vec(jj)/2))*ii(:,jj)'); %ii(:,jj),-ij(:,jj),RR(jj)\s/2));
L = exp(KK(:,:,jj)+IRI(:,:,jj) +2*iiRR(:,jj)*(ii(:,jj))');
AA(jj)= sum(sum(A.*L)); 
% add measurement/system noise
end
S = tt.*AA;
S = S + exp(2*X(1,D+1)) + exp(2*X(1,D+2)); 
% second: centralize moments
S = S - M.^2; 
%M_vec(jj) = M;
%S_vec(jj) = S;
%M = M_vec;
%S = S_vec;
time_gpPo = toc; disp('time_gpPo_2'); disp(time_gpPo)

%{

sumA(jj) = sum(sum(A)); 
end
time_gpPo = toc; disp('time_gpPo_2'); disp(time_gpPo)
S = tt.*sumA;
% add measurement/system noise
S = S + exp(2*X(1,D+1)) + exp(2*X(1,D+2)); 
% second: centralize moments
S = S - M.^2; 
%}

%time_gpPo = toc; disp('time_gpPo_3'); disp(time_gpPo)
%disp('hi')